# ET Social Intelligence System

**Transform ET's social comment section from passive engagement metrics into a proprietary market research engine.**

## What This Does

This system analyzes social media comments from Entertainment Tonight's platforms to produce actionable intelligence briefs that:

- **Track mass-market perception** of talent and IP in real-time
- **Identify sentiment velocity** - catch reputation shifts before they become crises
- **Detect storyline fatigue** - know when the audience is over it
- **Separate hype from reality** - distinguish Twitter bubbles from general audience sentiment
- **Provide risk radar** for casting, marketing, and damage control decisions

## Key Features

### üéØ Auto-Detection
- Celebrities, shows, and IP mentioned in comments
- Coupled entities (Taylor+Travis, Blake+It Ends With Us)
- Active storylines (lawsuits, relationships, controversies)
- No manual tagging required

### üìä Context-Aware Sentiment
- Understands entertainment language ("she ate" = positive)
- Detects sarcasm and stan culture
- Tracks 8 emotion categories including "fatigue"
- Emotion-based insights, not just positive/negative

### ‚ö° Velocity Alerts
- Flags sentiment drops/spikes ‚â•30% in 72 hours
- Identifies which assets need attention NOW
- Historical comparison shows if trends are new or recurring

### üìà Professional Reports
- Executive summary with key findings
- Visual charts and data tables
- Velocity risk radar
- Storyline tracking
- Exportable PDF format

## Installation

### 1. Clone or Download
```bash
cd /home/claude/et_social_intelligence
```

### 2. Install Dependencies
```bash
pip install --break-system-packages -r requirements.txt
```

### 3. (Optional) Set OpenAI API Key
For better sentiment accuracy using GPT-4o-mini:
```bash
export OPENAI_API_KEY="your-key-here"
```

**Note:** System works without API using rule-based analysis (free but less accurate).

## Quick Start

### Method 1: Interactive CLI (Easiest)
```bash
python3 cli.py
```

Follow the menu prompts to:
1. Import CSV files
2. Generate intelligence briefs
3. View database stats

### Method 2: Python Script
```python
from pipeline import ETIntelligencePipeline
from report_generator import IntelligenceBriefGenerator

# Initialize
pipeline = ETIntelligencePipeline(use_api=False)  # Set True for GPT-4o-mini

# Process new data
df, entities = pipeline.process_new_data(
    csv_path='instagram_comments.csv',
    platform='instagram',
    post_metadata={
        'post_url': 'https://instagram.com/p/ABC123',
        'subject': 'Taylor Swift',
        'post_caption': 'Taylor arrives at Chiefs game'
    }
)

# Generate intelligence brief
brief = pipeline.generate_intelligence_brief(
    start_date='2024-01-01',
    platforms=['instagram']
)

# Create PDF report
generator = IntelligenceBriefGenerator()
pdf_path = generator.generate_report(brief)
print(f"Report saved: {pdf_path}")
```

## CSV Data Format

### Instagram CSV
Your CSV should have these columns (names are flexible):
- `username` or `user` or `author`
- `comment` or `text` or `content`
- `timestamp` or `date` or `created_at`
- `likes` (optional)

### YouTube CSV
Similar format:
- `Author` or `Channel Name`
- `Comment` or `Text`
- `Published At` or `Date`
- `Likes` (optional)

### Example CSV
```csv
username,comment,timestamp,likes
@taylorswiftfan,OMG she ate this look üî•,2024-11-20 14:30:00,245
@realitytv_lover,I'm so over this storyline honestly,2024-11-20 14:35:00,12
@moviebuff2024,They're perfect together!! ‚ù§Ô∏è,2024-11-20 14:40:00,89
```

## How to Get Instagram/YouTube Comments

### Option 1: Manual Export Tools
- **Apify** (recommended): https://apify.com/apify/instagram-comment-scraper
- **Instaloader**: Command-line tool for Instagram
- **YouTube Comment Scraper**: Various Chrome extensions

### Option 2: Official APIs
- Instagram Graph API (if you have ET's business account access)
- YouTube Data API

### Option 3: Virtual Assistant
Hire a VA on Upwork to manually export comments weekly using browser tools.

## Configuration

Edit `config.py` to customize:

```python
# Processing settings
BATCH_SIZE = 50  # Comments per API batch
MIN_ENTITY_MENTIONS = 3  # Min mentions to track entity
COUPLE_THRESHOLD = 0.6  # Co-occurrence rate for relationships

# Velocity alerts
VELOCITY_WINDOW_HOURS = 72  # Track changes over 3 days
VELOCITY_ALERT_THRESHOLD = 0.3  # Alert at 30% change

# Seed relationships (manually maintained)
SEED_RELATIONSHIPS = [
    ["Travis Kelce", "Taylor Swift"],
    ["Blake Lively", "It Ends With Us"],
    # Add more as needed
]
```

## Output Files

### Processed Data
- `data/processed/` - CSV files with sentiment analysis
- `data/database/known_entities.json` - Growing entity database

### Reports
- `reports/ET_Intelligence_Brief_[timestamp].pdf` - Professional PDF
- `reports/intelligence_brief_[timestamp].json` - Raw data
- `reports/charts/` - Visualization images

## Cost Estimates

### Without API (Rule-Based)
- **Cost:** $0/month
- **Accuracy:** ~70-75%
- **Best for:** MVP testing, high-volume processing

### With GPT-4o-mini API
- **Cost:** ~$5-15/month for 10,000 comments
- **Accuracy:** ~85-90%
- **Best for:** Production use, executive reports

**API Pricing:**
- Input: $0.15 per 1M tokens
- Output: $0.60 per 1M tokens
- Typical comment analysis: ~50-100 tokens

## Workflow Example

### Monthly Intelligence Brief Process

1. **Monday (Data Collection)**
   - Export last 30 days of Instagram comments for top 20 ET posts
   - Export YouTube comments from key videos
   - Save as CSV files

2. **Tuesday (Processing)**
   ```bash
   python3 cli.py
   # Select Option 1, import all CSV files
   # Takes 10-30 minutes depending on volume
   ```

3. **Wednesday (Report Generation)**
   ```bash
   python3 cli.py
   # Select Option 2, generate brief with 30-day filter
   # Customize filters as needed
   ```

4. **Thursday (Distribution)**
   - Review PDF report
   - Add executive notes if needed
   - Distribute to Paramount stakeholders

## Troubleshooting

### "Could not detect required columns"
Your CSV column names don't match expected patterns. Check that you have:
- Username/author column
- Comment/text column  
- Timestamp/date column

### "No processed data found"
You need to import CSV files first using Option 1 in the CLI.

### API errors
If using OpenAI API:
1. Verify API key: `echo $OPENAI_API_KEY`
2. Check account has credits: https://platform.openai.com/usage
3. Fall back to rule-based: Set `use_api=False`

### Low entity detection
- Increase `MIN_ENTITY_MENTIONS` in config.py
- Add known entities to `data/database/known_entities.json`
- Provide better `post_subject` metadata when importing

## Roadmap

### Phase 1 (MVP - Current)
- ‚úÖ CSV ingestion
- ‚úÖ Entity auto-detection
- ‚úÖ Sentiment analysis
- ‚úÖ PDF reports
- ‚úÖ Velocity tracking

### Phase 2 (Next 30 Days)
- [ ] Instagram API integration
- [ ] YouTube API integration  
- [ ] Interactive web dashboard
- [ ] Automated scheduling
- [ ] Email report delivery

### Phase 3 (Future)
- [ ] Competitive benchmarking (vs E! News, TMZ)
- [ ] Demographic inference from usernames/bios
- [ ] Influencer identification
- [ ] Predictive modeling (sentiment forecasting)
- [ ] Multi-language support

## Support

For questions or issues:
1. Check this README
2. Review sample code in `pipeline.py`
3. Run with `--debug` flag for detailed logs

## License

Internal use only - CBS/Paramount.

---

**Built by Joe | CBS Marketing**
*Transforming social engagement into strategic intelligence*
